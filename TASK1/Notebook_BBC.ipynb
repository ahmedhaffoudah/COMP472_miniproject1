{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c74cfba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./bbc/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcc55aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1c40d5",
   "metadata": {},
   "source": [
    "## LOADING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbc90b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_files(DATA_DIR, encoding = \"latin1\")\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01e3c2e",
   "metadata": {},
   "source": [
    "## PLOTING THE DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21d3ad40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels, counts = np.unique(y, return_counts=True)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(data.target_names, counts)\n",
    "ax.set_ylabel('Number of Instances')\n",
    "ax.set_title('BBC-distribution')\n",
    "\n",
    "plt.savefig(\"BBC-distribution.pdf\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a30fb4",
   "metadata": {},
   "source": [
    "## PREPROSSESSING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04635830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f8985e",
   "metadata": {},
   "source": [
    "## SPLITTING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ef8a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf889a",
   "metadata": {},
   "source": [
    "## TRAINING THE DATA - SMOOTHING = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65af0609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5727671b",
   "metadata": {},
   "source": [
    "## TRAINING THE DATA - SMOOTHING = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcc8a7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.0001)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf1 = MultinomialNB(alpha=0.0001)\n",
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cca349",
   "metadata": {},
   "source": [
    "## TRAINING THE DATA - SMOOTHING = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04d249e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.9)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf2 = MultinomialNB(alpha=0.9)\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5236645a",
   "metadata": {},
   "source": [
    "##  CONFUSION MATRICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "931673bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = clf.predict(X_test)\n",
    "cMatrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aebecf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred1 = clf1.predict(X_test)\n",
    "cMatrix1 = confusion_matrix(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ee976d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred2 = clf2.predict(X_test)\n",
    "cMatrix2 = confusion_matrix(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69589755",
   "metadata": {},
   "source": [
    "## CLASSIFICATION REPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8141f6a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cReport = classification_report(y_test, y_pred, target_names=data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc370417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cReport1 = classification_report(y_test, y_pred1, target_names=data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "702233fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cReport2 = classification_report(y_test, y_pred2, target_names=data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5a5423",
   "metadata": {},
   "source": [
    "## ACCURACIES AND F1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28d08994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68fda57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "accuracy1 = accuracy_score(y_test, y_pred1) * 100\n",
    "f1_macro1 = f1_score(y_test, y_pred1, average='macro')\n",
    "f1_weighted1 = f1_score(y_test, y_pred1, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7fe29de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "accuracy2 = accuracy_score(y_test, y_pred2) * 100\n",
    "f1_macro2 = f1_score(y_test, y_pred2, average='macro')\n",
    "f1_weighted2 = f1_score(y_test, y_pred2, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f80e31",
   "metadata": {},
   "source": [
    "## PRIORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c3dff34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, counts = np.unique(data.target, return_counts=True)\n",
    "labels_str = np.array(data.target_names)[labels]\n",
    "labels_count = dict(zip(labels_str, counts))\n",
    "total = np.sum(counts)\n",
    "prior_b = labels_count['business']/total \n",
    "prior_e = labels_count['entertainment']/total\n",
    "prior_p = labels_count['politics']/total\n",
    "prior_s = labels_count['sport']/total\n",
    "prior_t = labels_count['tech']/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd65bb7",
   "metadata": {},
   "source": [
    "## TOTAL WORDS IN EACH CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca63cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X.toarray()\n",
    "words_by_class = np.zeros_like(np.arange(5))\n",
    "zero_f_by_class = np.zeros_like(np.arange(5))\n",
    "for i in range(y.shape[0]):\n",
    "    if y[i] == 0:\n",
    "        words_by_class[0] += np.sum(a[i])\n",
    "        zero_f_by_class[0] += np.count_nonzero(a[i]==0) \n",
    "    elif y[i] == 1:\n",
    "        words_by_class[1] += np.sum(a[i])\n",
    "        zero_f_by_class[1] += np.count_nonzero(a[i]==0) \n",
    "    elif y[i] == 2:\n",
    "        words_by_class[2] += np.sum(a[i])\n",
    "        zero_f_by_class[2] += np.count_nonzero(a[i]==0) \n",
    "    elif y[i] == 3:\n",
    "        words_by_class[3] += np.sum(a[i])\n",
    "        zero_f_by_class[3] += np.count_nonzero(a[i]==0) \n",
    "    elif y[i] == 4:\n",
    "        words_by_class[4] += np.sum(a[i])\n",
    "        zero_f_by_class[4] += np.count_nonzero(a[i]==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382d1b38",
   "metadata": {},
   "source": [
    "## % WITH FREQUENCY 0 IN EACH CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a21671cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_percentages = []\n",
    "for i in range(5):\n",
    "    zero_percentages.append(zero_f_by_class[i]/(a.shape[1]*counts[i]) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc6361d",
   "metadata": {},
   "source": [
    "## # AND % OF WORDS WITH FREQUENCY 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7d37599",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_f_one = np.count_nonzero(a==1)\n",
    "percentage_f_one = nb_f_one/(a.shape[0]*a.shape[1])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5aa89",
   "metadata": {},
   "source": [
    "## FAV WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6553157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#22865: royal\n",
    "#23400: scottish\n",
    "\n",
    "rows_sums = np.sum(a, axis = 0)\n",
    "prob_favs = [rows_sums[22865]/np.sum(words_by_class), rows_sums[23400]/np.sum(words_by_class)]\n",
    "log_prob_favs = np.log10(prob_favs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c81fded",
   "metadata": {},
   "source": [
    "## FILE OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9cff1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = '***************************************************************************\\n\\n'\n",
    "with open('bbc-performance.txt', 'a') as f:\n",
    "#     f.write(\"%s(a) MultinomialNB default values, try 1\\n\\n\" % stars)\n",
    "    f.write(\"%s(b) CONFUSION MATIRX\\n\\n\" % stars)\n",
    "    np.savetxt(f, cMatrix, fmt ='%3.d', delimiter='     ')\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(\"%s(c) CLASSIFICATION REPORT\\n\\n%s\\n\\n\" % (stars, cReport))\n",
    "    f.write(\"%s(d)\\n\\nACCURACY = %.2f%%\\n\\nMACRO-AVERAGE F1 = %.2f\\n\\nWEIGHTED-AVERAGE F1 = %.2f\\n\\n\" % (stars, accuracy, f1_macro, f1_weighted))\n",
    "#     f.write(\"%s(e) PRIORS\\n\\n%s\\n\\nTOTAL = %.d\\n\\nBUSINESS PRIOR = %.2f\\n\\nENTERTAINMENT PRIOR = %.2f\\n\\nPOLITICS PRIOR = %.2f\\n\\nSPORT PRIOR = %.2f\\n\\nTECH PRIOR = %.2f\\n\\n\" % (stars, labels_count, total, prior_b, prior_e, prior_p, prior_s, prior_t))\n",
    "#     f.write(\"%s(f) VOCABULARY SIZE\\n\\nWhen we used the Countvectorizer, it did not take duplicates.\\nWe ended up with an array where the rows represented the documents and the columns represented the words.\\nTherefore, in order to calculate the size of the vocabulary, we count how many columns the array has.\\n\\nVOCABULARY SIZE = %.d\\n\\n\" % (stars, X.shape[1]))\n",
    "#     f.write(\"%s(g) NUMBER OF WORD-TOKENS IN EACH CLASS\\n\\nBUSINESS = %d\\n\\nENTERTAINMENT = %d\\n\\nPOLITICS = %d\\n\\nSPORTS = %d\\n\\nTECH = %d\\n\\n\" % (stars, words_by_class[0], words_by_class[1], words_by_class[2], words_by_class[3], words_by_class[4]))\n",
    "#     f.write(\"%s(h) NUMBER OF WORD-TOKENS IN THE ENTIRE CORPUS\\n\\nCOUNT = %d\\n\\n\" % (stars, np.sum(words_by_class)))\n",
    "#     f.write(\"%s(i) NUMBER AND PERCENTAGE OF WORD | FRENQUENCY = 0, FOR EACH CLASS\\n\\nBUSINESS = %d --> %.2f%%\\n\\nENTERTAINMENT = %d --> %.2f%%\\n\\nPOLITICS = %d --> %.2f%%\\n\\nSPORTS = %d --> %.2f%%\\n\\nTECH = %d --> %.2f%%\\n\\n\" % (stars, zero_f_by_class[0], zero_percentages[0], zero_f_by_class[1], zero_percentages[1], zero_f_by_class[2], zero_percentages[2], zero_f_by_class[3], zero_percentages[3], zero_f_by_class[4], zero_percentages[4]))\n",
    "#     f.write(\"%s(j) NUMBER AND PERCENTAGE OF WORD | FRENQUENCY = 1\\n\\nCOUNT = %d --> %.2f%%\\n\\n\" % (stars, nb_f_one, percentage_f_one))\n",
    "#     f.write(\"%s(k) FAV WORDS\\n\\n1. royal (index: 22865) --> log_prob = %.2f\\n\\n2. scottish (index: 23400) --> log_prob = %.2f\\n\\n\" % (stars, log_prob_favs[0], log_prob_favs[1]))\n",
    "    \n",
    "    #---------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "#     f.write(\"%s(a) MultinomialNB default values, try 2\\n\\n\" % stars)\n",
    "    f.write(\"%s(b) CONFUSION MATIRX\\n\\n\" % stars)\n",
    "    np.savetxt(f, cMatrix, fmt ='%3.d', delimiter='     ')\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(\"%s(c) CLASSIFICATION REPORT\\n\\n%s\\n\\n\" % (stars, cReport))\n",
    "    f.write(\"%s(d)\\n\\nACCURACY = %.2f%%\\n\\nMACRO-AVERAGE F1 = %.2f\\n\\nWEIGHTED-AVERAGE F1 = %.2f\\n\\n\" % (stars, accuracy, f1_macro, f1_weighted))\n",
    "#     f.write(\"%s(e) PRIORS\\n\\n%s\\n\\nTOTAL = %.d\\n\\nBUSINESS PRIOR = %.2f\\n\\nENTERTAINMENT PRIOR = %.2f\\n\\nPOLITICS PRIOR = %.2f\\n\\nSPORT PRIOR = %.2f\\n\\nTECH PRIOR = %.2f\\n\\n\" % (stars, labels_count, total, prior_b, prior_e, prior_p, prior_s, prior_t))\n",
    "#     f.write(\"%s(f) VOCABULARY SIZE\\n\\nWhen we used the Countvectorizer, it did not take duplicates.\\nWe ended up with an array where the rows represented the documents and the columns represented the words.\\nTherefore, in order to calculate the size of the vocabulary, we count how many columns the array has.\\n\\nVOCABULARY SIZE = %.d\\n\\n\" % (stars, X.shape[1]))\n",
    "#     f.write(\"%s(g) NUMBER OF WORD-TOKENS IN EACH CLASS\\n\\nBUSINESS = %d\\n\\nENTERTAINMENT = %d\\n\\nPOLITICS = %d\\n\\nSPORTS = %d\\n\\nTECH = %d\\n\\n\" % (stars, words_by_class[0], words_by_class[1], words_by_class[2], words_by_class[3], words_by_class[4]))\n",
    "#     f.write(\"%s(h) NUMBER OF WORD-TOKENS IN THE ENTIRE CORPUS\\n\\nCOUNT = %d\\n\\n\" % (stars, np.sum(words_by_class)))\n",
    "#     f.write(\"%s(i) NUMBER AND PERCENTAGE OF WORD | FRENQUENCY = 0, FOR EACH CLASS\\n\\nBUSINESS = %d --> %.2f%%\\n\\nENTERTAINMENT = %d --> %.2f%%\\n\\nPOLITICS = %d --> %.2f%%\\n\\nSPORTS = %d --> %.2f%%\\n\\nTECH = %d --> %.2f%%\\n\\n\" % (stars, zero_f_by_class[0], zero_percentages[0], zero_f_by_class[1], zero_percentages[1], zero_f_by_class[2], zero_percentages[2], zero_f_by_class[3], zero_percentages[3], zero_f_by_class[4], zero_percentages[4]))\n",
    "#     f.write(\"%s(j) NUMBER AND PERCENTAGE OF WORD | FRENQUENCY = 1\\n\\nCOUNT = %d --> %.2f%%\\n\\n\" % (stars, nb_f_one, percentage_f_one))\n",
    "#     f.write(\"%s(k) FAV WORDS\\n\\n1. royal (index: 22865) --> log_prob = %.2f\\n\\n2. scottish (index: 23400) --> log_prob = %.2f\\n\\n\" % (stars, log_prob_favs[0], log_prob_favs[1]))\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "#     f.write(\"%s(a) MultinomialNB default values, smoothing = 0.0001\\n\\n\" % stars)\n",
    "    f.write(\"%s(b) CONFUSION MATIRX\\n\\n\" % stars)\n",
    "    np.savetxt(f, cMatrix1, fmt ='%3.d', delimiter='     ')\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(\"%s(c) CLASSIFICATION REPORT\\n\\n%s\\n\\n\" % (stars, cReport1))\n",
    "    f.write(\"%s(d)\\n\\nACCURACY = %.2f%%\\n\\nMACRO-AVERAGE F1 = %.2f\\n\\nWEIGHTED-AVERAGE F1 = %.2f\\n\\n\" % (stars, accuracy1, f1_macro1, f1_weighted1))\n",
    "#     f.write(\"%s(e) PRIORS\\n\\n%s\\n\\nTOTAL = %.d\\n\\nBUSINESS PRIOR = %.2f\\n\\nENTERTAINMENT PRIOR = %.2f\\n\\nPOLITICS PRIOR = %.2f\\n\\nSPORT PRIOR = %.2f\\n\\nTECH PRIOR = %.2f\\n\\n\" % (stars, labels_count, total, prior_b, prior_e, prior_p, prior_s, prior_t))\n",
    "#     f.write(\"%s(f) VOCABULARY SIZE\\n\\nWhen we used the Countvectorizer, it did not take duplicates.\\nWe ended up with an array where the rows represented the documents and the columns represented the words.\\nTherefore, in order to calculate the size of the vocabulary, we count how many columns the array has.\\n\\nVOCABULARY SIZE = %.d\\n\\n\" % (stars, X.shape[1]))\n",
    "#     f.write(\"%s(g) NUMBER OF WORD-TOKENS IN EACH CLASS\\n\\nBUSINESS = %d\\n\\nENTERTAINMENT = %d\\n\\nPOLITICS = %d\\n\\nSPORTS = %d\\n\\nTECH = %d\\n\\n\" % (stars, words_by_class[0], words_by_class[1], words_by_class[2], words_by_class[3], words_by_class[4]))\n",
    "#     f.write(\"%s(h) NUMBER OF WORD-TOKENS IN THE ENTIRE CORPUS\\n\\nCOUNT = %d\\n\\n\" % (stars, np.sum(words_by_class)))\n",
    "#     f.write(\"%s(i) NUMBER AND PERCENTAGE OF WORD | FRENQUENCY = 0, FOR EACH CLASS\\n\\nBUSINESS = %d --> %.2f%%\\n\\nENTERTAINMENT = %d --> %.2f%%\\n\\nPOLITICS = %d --> %.2f%%\\n\\nSPORTS = %d --> %.2f%%\\n\\nTECH = %d --> %.2f%%\\n\\n\" % (stars, zero_f_by_class[0], zero_percentages[0], zero_f_by_class[1], zero_percentages[1], zero_f_by_class[2], zero_percentages[2], zero_f_by_class[3], zero_percentages[3], zero_f_by_class[4], zero_percentages[4]))\n",
    "#     f.write(\"%s(j) NUMBER AND PERCENTAGE OF WORD | FRENQUENCY = 1\\n\\nCOUNT = %d --> %.2f%%\\n\\n\" % (stars, nb_f_one, percentage_f_one))\n",
    "#     f.write(\"%s(k) FAV WORDS\\n\\n1. royal (index: 22865) --> log_prob = %.2f\\n\\n2. scottish (index: 23400) --> log_prob = %.2f\\n\\n\" % (stars, log_prob_favs[0], log_prob_favs[1]))\n",
    "    \n",
    "    #---------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "#     f.write(\"%s(a) MultinomialNB default values, smoothing = 0.9\\n\\n\" % stars)\n",
    "    f.write(\"%s(b) CONFUSION MATIRX\\n\\n\" % stars)\n",
    "    np.savetxt(f, cMatrix2, fmt ='%3.d', delimiter='     ')\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(\"%s(c) CLASSIFICATION REPORT\\n\\n%s\\n\\n\" % (stars, cReport2))\n",
    "    f.write(\"%s(d)\\n\\nACCURACY = %.2f%%\\n\\nMACRO-AVERAGE F1 = %.2f\\n\\nWEIGHTED-AVERAGE F1 = %.2f\\n\\n\" % (stars, accuracy2, f1_macro2, f1_weighted2))\n",
    "#     f.write(\"%s(e) PRIORS\\n\\n%s\\n\\nTOTAL = %.d\\n\\nBUSINESS PRIOR = %.2f\\n\\nENTERTAINMENT PRIOR = %.2f\\n\\nPOLITICS PRIOR = %.2f\\n\\nSPORT PRIOR = %.2f\\n\\nTECH PRIOR = %.2f\\n\\n\" % (stars, labels_count, total, prior_b, prior_e, prior_p, prior_s, prior_t))\n",
    "#     f.write(\"%s(f) VOCABULARY SIZE\\n\\nWhen we used the Countvectorizer, it did not take duplicates.\\nWe ended up with an array where the rows represented the documents and the columns represented the words.\\nTherefore, in order to calculate the size of the vocabulary, we count how many columns the array has.\\n\\nVOCABULARY SIZE = %.d\\n\\n\" % (stars, X.shape[1]))\n",
    "#     f.write(\"%s(g) NUMBER OF WORD-TOKENS IN EACH CLASS\\n\\nBUSINESS = %d\\n\\nENTERTAINMENT = %d\\n\\nPOLITICS = %d\\n\\nSPORTS = %d\\n\\nTECH = %d\\n\\n\" % (stars, words_by_class[0], words_by_class[1], words_by_class[2], words_by_class[3], words_by_class[4]))\n",
    "#     f.write(\"%s(h) NUMBER OF WORD-TOKENS IN THE ENTIRE CORPUS\\n\\nCOUNT = %d\\n\\n\" % (stars, np.sum(words_by_class)))\n",
    "#     f.write(\"%s(i) NUMBER AND PERCENTAGE OF WORD | FRENQUENCY = 0, FOR EACH CLASS\\n\\nBUSINESS = %d --> %.2f%%\\n\\nENTERTAINMENT = %d --> %.2f%%\\n\\nPOLITICS = %d --> %.2f%%\\n\\nSPORTS = %d --> %.2f%%\\n\\nTECH = %d --> %.2f%%\\n\\n\" % (stars, zero_f_by_class[0], zero_percentages[0], zero_f_by_class[1], zero_percentages[1], zero_f_by_class[2], zero_percentages[2], zero_f_by_class[3], zero_percentages[3], zero_f_by_class[4], zero_percentages[4]))\n",
    "#     f.write(\"%s(j) NUMBER AND PERCENTAGE OF WORD | FRENQUENCY = 1\\n\\nCOUNT = %d --> %.2f%%\\n\\n\" % (stars, nb_f_one, percentage_f_one))\n",
    "#     f.write(\"%s(k) FAV WORDS\\n\\n1. royal (index: 22865) --> log_prob = %.2f\\n\\n2. scottish (index: 23400) --> log_prob = %.2f\\n\\n\" % (stars, log_prob_favs[0], log_prob_favs[1]))\n",
    "    \n",
    "    \n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
