***************************************************************************

(a) MultinomialNB default values

***************************************************************************

(b) CONFUSION MATIRX

102       1       3       0       2
  0      66       2       0       0
  2       0      84       0       0
  0       0       0      99       0
  0       1       0       0      83


***************************************************************************

(c) CLASSIFICATION REPORT

               precision    recall  f1-score   support

     business       0.98      0.94      0.96       108
entertainment       0.97      0.97      0.97        68
     politics       0.94      0.98      0.96        86
        sport       1.00      1.00      1.00        99
         tech       0.98      0.99      0.98        84

     accuracy                           0.98       445
    macro avg       0.97      0.98      0.98       445
 weighted avg       0.98      0.98      0.98       445


***************************************************************************

(d)

ACCURACY = 97.53%

MACRO-AVERAGE F1 = 0.98

WEIGHTED-AVERAGE F1 = 0.98



***************************************************************************

(e) PRIORS

{'business': 510, 'entertainment': 386, 'politics': 417, 'sport': 511, 'tech': 401}

TOTAL = 2225

BUSINESS PRIOR = 0.23

ENTERTAINMENT PRIOR = 0.17

POLITICS PRIOR = 0.19

SPORT PRIOR = 0.23

TECH PRIOR = 0.18

***************************************************************************

(f) VOCABULARY SIZE

When we used the Countvectorizer, it did not take duplicates.
We ended up with an array where the rows represented the documents and the columns represented the words.
Therefore, in order to calculate the size of the vocabulary, we count how many columns the array has.

VOCABULARY SIZE = 29421

